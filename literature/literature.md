## Read papers

- [Learning deep representations by mutual information estimation and maximization](https://arxiv.org/pdf/1808.06670.pdf):
  - formalizes DIM, which simultaneously estimates and maximizes the mututal inforamtion between input data and learned high-level representations
  - uses adversarial learning to have desired statistical characteristics
  - can prioritize local and global information -> representations of segmentations much better than whole image
  - two measures of representation quality: 
    - Mutual Information Neural Estimation (MINE) (Belghazi et al., 2018)
    - Neural dependency measure (NDM) (based on Brakel & Benngio, 2017)
  - representation usable and suitable for many different classification tasks
  
Critics paper
- [On mutual inforamtion maximization for representations learning](https://arxiv.org/pdf/1907.13625.pdf)

- [Computing the Unique information](https://arxiv.org/pdf/1709.07487.pdf)
- [Factoized Mututal Information Maximization](https://arxiv.org/abs/1906.05460)
- [Deep image prior](https://sites.skoltech.ru/app/data/uploads/sites/25/2018/04/deep_image_prior.pdf)
- [Mutual information Neural Estimation](https://arxiv.org/pdf/1801.04062.pdf)


Second phase:
- [Wasserstein metric](https://link.springer.com/chapter/10.1007/978-3-030-26980-7_73)
- [Wasserstein metric on images](http://proceedings.mlr.press/v97/dukler19a.html)
- [Wasserstein Diffusion Tikhonov regularisation](https://arxiv.org/abs/1909.06860)


Image deformations:
- [adversarial deformations](https://openreview.net/forum?id=Hk4dFjR5K7)
  - affiliated [Github repo](https://gitlab.math.ethz.ch/tandrig/ADef)

- [Sinkhole](http://proceedings.mlr.press/v97/wong19a.html)
